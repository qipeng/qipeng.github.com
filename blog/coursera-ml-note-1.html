<!DOCTYPE html>
<html lang="en">
<head>
 <meta charset="utf-8">

  <!-- Always force latest IE rendering engine (even in intranet) & Chrome Frame
       Remove this if you use the .htaccess -->
  <meta http-equiv="X-UA-Compatible" content="">
  <meta http-equiv="Content-Type" content="text/html; charset=utf8" />
  <meta name="robots" content="all" />
  <meta name="googlebot" content="all" />

  <title>[Coursera] Machine Learning Notes - Week 1-3</title>
  <meta name="description" content="Course Notes for machine learning course offered by Andrew Ng at coursera.org
">
  <meta name="keywords" content="">
  <meta name="author" content="Peng Qi">

  <!--  Mobile viewport optimized: j.mp/bplateviewport -->
  <meta name="viewport" content="">

	<link href="//netdna.bootstrapcdn.com/bootswatch/2.3.2/cerulean/bootstrap.min.css" rel="stylesheet"> 
    
     
  <link rel="stylesheet" href="/media/css/syntax.css" type="text/css">
  <link rel="stylesheet" href="/media/js/fancybox/jquery.fancybox-1.3.4.css" type="text/css">
  <link rel="stylesheet" href="/media/js/nivo-slider/themes/light/light.css" type="text/css" media="screen" />
  <link rel="stylesheet" href="/media/js/nivo-slider/nivo-slider.css" type="text/css" media="screen" />
  <link href='http://fonts.googleapis.com/css?family=Telex' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/media/css/site.css" type="text/css">
   
  
  <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
    <script src="media/js/html5shiv.js"></script>
  <![endif]-->

    <!-- Fav and touch icons -->
  <link rel="shortcut icon" href="favicon.ico">
      
      </head>

<body>
<div class="container-fluid">
	<div class="row-fluid">
		<div class="span12">
			<div class="navbar">
				<div class="navbar-inner">
					<div class="container-fluid" style="padding:0;border-bottom:1px solid #ccc">
						 <a data-target=".navbar-responsive-collapse" data-toggle="collapse" class="btn btn-navbar"><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></a> <a href="#" class="brand">Peng <span class="surname">Qi</span></a>
						<div class="nav-collapse collapse navbar-responsive-collapse">
                                    <ul class="nav">
                <li >
            <a title="Home Page"
                class="home"
                href="/index.html">
                Home
            </a>
        </li>        <li >
            <a title="Research"
                class="research"
                href="/research">
                Research
            </a>
        </li>        <li class="active">
            <a title="Blog"
                class="active blog"
                href="/blog">
                Blog
            </a>
        </li>        <li >
            <a title="Software"
                class="software"
                href="/software">
                Software
            </a>
        </li>        <li >
            <a title="Misc"
                class="misc"
                href="/misc">
                Me &amp; My ...
            </a>
        </li>    </ul>
						</div>
					</div>
				</div>
				
			</div>
            		</div>
	</div>
	<div class="row-fluid">
		<div class="span9">
        <div id="container">
                <section class="content">
          <article class="post">

<ul class="breadcrumb">
    <li>
        <a href="/blog">Blog</a> <span class="divider">/</span>
    </li>
    <li class="active">
        [Coursera] Machine Learning Notes - Week 1-3
    </li>
</ul>

<time datetime="2012-09-01">
    Sat, 01 Sep 2012
</time>
<div class="title"><h1 >
    [Coursera] Machine Learning Notes - Week 1-3
</h1></div>


<div class="postcontent">
<p>
I recently enrolled in Stanford University&#8217;s Machine Learning open course on
<a href="http://coursera.org/" target="_blank">coursera.org</a>, which is taught
by esteemed <a href="http://ai.stanford.edu/~ang/" target="_blank">Prof Andrew Ng</a>.
I&#8217;ll take some notes that are important to me (and probably many machine learning
rookies), and hope this would help in later studies. (Disclosure of homework, 
homework solutions, and other materials are somehow a bad thing to do, 
for copyright problems or unfairness of prospective students of that course,
but I guess notes would be&nbsp;fine.)</p>

<p>
By the way, the <span class="caps">UI</span> of coursera.org is quite simple and informative, but I guess
somehow they should try to unify the appearance of homepage and inside-course pages,
and use more reliable, preferably official,&nbsp;subtitles.
</p>

<p>
So here are the notes from Week&nbsp;1-3.
</p>

<p>
<div class='title'><h3>Week 1: Introduction and Linear&nbsp;Regression</h3></div>
<ul class='news'>
<li><span class='lighter'>Machine learning</span> is some method or algorithm, that improves given experience
<img alt="E" src="http://www.texify.com/img/%5Cnormalsize%5C%21E.gif" align=center border=0> 
with regard to some performance measure
<img alt="P" src="http://www.texify.com/img/%5Cnormalsize%5C%21P.gif" align=center border=0> 
on a task <img alt="T" src="http://www.texify.com/img/%5Cnormalsize%5C%21T.gif" align=center border=0>.
(Paraphrased from Tom Mitchell, 1998. I cannot agree&nbsp;more!)</li>
<li><span class='lighter'>Supervised learning</span> is learning problems where we are given the &#8220;right answers&#8221;,
and asked to give the &#8220;map&#8221; from input values to prediction. Supervised learning
mainly consist of regression problems (where the output is continuous) and classification
problems (where the output takes only a few discrete&nbsp;values).</li>
<li><span class='lighter'>Unsupervised learning</span>, on the other hand, has no predefined output value for each input
datum. In such tasks, we usually need to tell the structure of the input data (which is called
&#8220;clustering problem&#8221;), or separate meaningful information from somewhat mixed input (e.g.
the cocktail party problem, where sound recorded by two speakers are used to recover
the sole music and human voice from the scene where they were&nbsp;recorded).</li>
<li>Usually, in supervised learning, our knowledge of the map from input to output
is given as a parametric <span class='lighter'>hypothesis</span>, with a <span class='lighter'>
cost function</span> evaluating how good the hypothesis is (given certain choice of&nbsp;parameters).</li>
<li><span class='lighter'>Gradient descent</span> updates the parameters with update rule 
<img alt="-\alpha {\partial J(\theta)\over \partial \theta}" src="http://www.texify.com/img/%5Cnormalsize%5C%21-%5Calpha%20%7B%5Cpartial%20J%28%5Ctheta%29%5Cover%20%5Cpartial%20%5Ctheta%7D.gif" align=center border=0>, with <img alt="J" src="http://www.texify.com/img/%5Cnormalsize%5C%21J.gif" align=center border=0> being the cost function, <img alt="\theta" src="http://www.texify.com/img/%5Cnormalsize%5C%21%5Ctheta.gif" align=center border=0> the parameter(s), and <img alt="\alpha" src="http://www.texify.com/img/%5Cnormalsize%5C%21%5Calpha.gif" align=center border=0> the <span class='lighter'>learning rate</span>. Gradient descent can find local minima (maxima) for all functions, but global optima is guaranteed for convex&nbsp;functions.</li>
</ul>
</p>

<p>
I skipped the review of linear algebra there. For that part, the
best help you can find would be a textbook on linear&nbsp;algebra.
</p>

<p>
<div class='title'><h3>Week 2: Multivariate Linear&nbsp;Regression</h3></div>
<ul class='news'>
<li>Most <span class='lighter'>multivariate gradient descent</span> problems involve
multivariate calculus, so to put this into practice, a textbook is still the best
suggestion I can&nbsp;offer.</li>
<li>Linear regression model can do much more than linear regression. <span class='lighter'>
Polynomial regression</span>, for example, can be done with linear regression model
by adding additional features that are powers of certain original features.
<span class='lighter'>Nonlinear regression</span> like square roots works well,&nbsp;too.</li>
<li><span class='lighter'>Normal equation</span> offers the possibility of solving linear
regression analytically. This solution is essentially obtained by setting the derivative 
linear regression&#8217;s cost function to zero (since the cost function is strictly convex,
such solution is guaranteed global optimal). However, since matrix inverse (pseudo inverse 
for non-invertible / singular matrices) operation is costly, this method cannot scale
well to high dimensional&nbsp;problems.</li>
<li>When your gradient descent doesn&#8217;t work well, try shrinking your <span class='lighter'>learning rate</span>. When it converges too slowly, try amplifying your learning rate. A good way to do that is using a factor of about 3x instead of 10x, that is, use &#8220;0.001 0.003 0.01 0.03 0.1 0.3 1&#8221; instead of &#8220;0.001 0.01 0.1 1&#8221;. I recently benefited from this softer approach in my research&nbsp;myself.</li>
<li>Gradient descent methods can benefit from <span class='lighter'>feature scaling</span> (stretch all features to approximately [-1, 1]), 
and <span class='lighter'>mean normalization</span> (subtracting mean from the feature values). These techniques make
gradient descent converge faster, without affecting the solution&nbsp;obtained.
</li>
</ul>
</p>

<p>
I also skipped the Octave part as I use Matlab, which is almost the same&nbsp;language.
</p>

<p>
<div class='title'><h3>Week 3: Logistic Regression and&nbsp;Regularization</h3></div>
<ul class='news'>
<li><span class='lighter'>Logistic regression</span> uses the logistic function (also
called sigmoid function) <img alt="\sigma(\theta^Tx) = {1\over 1+e^{-\theta^T x}}" src="http://www.texify.com/img/%5Cnormalsize%5C%21%5Csigma%28%5Ctheta%5ETx%29%20%3D%20%7B1%5Cover%201%2Be%5E%7B-%5Ctheta%5ET%20x%7D%7D.gif" align=center border=0> as the hypothesis function. To avoid non-convexity of cost function,
instead of the squared difference function linear regression used, logistic regression
used a cross-entropy style cost function <img alt="f(x) = -y\log(\sigma(\theta^Tx)) - (1-y)\log(1-\sigma(\theta^Tx))" src="http://www.texify.com/img/%5Cnormalsize%5C%21f%28x%29%20%3D%20-y%5Clog%28%5Csigma%28%5Ctheta%5ETx%29%29%20-%20%281-y%29%5Clog%281-%5Csigma%28%5Ctheta%5ETx%29%29.gif" align=center border=0>. This cost function
is convex, and thus friendly to gradient descent, for gradient descent methods are
guaranteed to obtain the global&nbsp;optima.</li>
<li>To generalize binary logistic regression to multiple class, the common 
option is the <span class='lighter'>&#8220;one-vs-all&#8221; algorithm</span>. For each class,
treat it as the positive class and all others as the negative class, we can train
a binary logistic classifier. All these classifiers together consists of a 
multi-class logistic regression&nbsp;classifier.</li>
<li><span class='lighter'>Regularization</span> can be used to avoid <span class='lighter'>
over-fitting</span>, where the parameters fits the hypothesis too well to the training
set that it cannot generalize well to new inputs. Regularization does this by
minimizing the impact of unnecessary features on the cost function with regard to
the regularization constant. However, when this constant is set too large,
necessary features could get suppressed, too, causing the model to <span class='lighter'>
under-fit</span> the data, in other words, introducing high bias towards
how the data should be&nbsp;interpreted.</li>
</ul>
</p>

<p>
<div class='title'><h3>See&nbsp;Also&#8230;</h3></div>
<a href="coursera-ml-note-2.html">[Coursera] Machine Learning Notes - Week 4-6</a><br>
<a href="coursera-ml-note-3.html">[Coursera] Machine Learning Notes - Week&nbsp;7-10</a>
</p></div>

<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'pengqishomepage'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>
</article>          </section>
                    </div>
		</div>
		<div class="span3">
        <div class="right-float">
<span class="lighter" >Related Posts</span><br/>
Older Post:
<a href="/blog/coursera-ml-note-2.html">[Coursera] Machine Learning Notes - Week 4-6</a>
<br/>

Newer Post:
<a href="/blog/putty-bat.html">Shortcut batch files that works with Putty</a>
</div>
<div class="right-float">
<span class="lighter" >Tags</span><br/>
<ul class="tags clear">
<li>
    <a class="small" href="/blog/tags/coursera.html">
        coursera
    </a>
</li>
<li>
    <a class="small" href="/blog/tags/machine_learning.html">
        machine_learning
    </a>
</li>
<li>
    <a class="small" href="/blog/tags/note.html">
        note
    </a>
</li>
</ul>
</div>
        <div class="right-float"><div id="sociallinks" style="font-size:10px;"></div>
            <div id="googletranslate"></div>
		</div>
	</div>
	<div class="row-fluid">
		<div class="span12">
        <footer>
      <div id="designlogo"><a href="http://qipeng.github.com/misc/homepage.html" target="_blank"><span class="lighter">Designed</span>by<br>
    <span style="padding-left:40px">Qi<span class="lighter">Peng</span></span></a>
    <br><span style="font-size:10px;text-align:center;">Powered by <a href="http://hyde.github.com/" target="_blank" class="hyde">hyde</a>.</span></div>
      <p style="text-align:center">&copy; <a href="http://qipeng.github.com/">Peng Qi</a>, 2011 &ndash; 2013. Hosted by <a href="http://www.github.com">GitHub</a>.</p>
  </footer>
		</div>
	</div>
</div>
  <!-- Javascript at the bottom for fast page loading -->

  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js"></script>
    <script src="//ajax.googleapis.com/ajax/libs/jqueryui/1.10.3/jquery-ui.min.js"></script>
    <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
  <script src="/media/js/nivo-slider/jquery.nivo.slider.pack.js" type="text/javascript"></script>
  <script> $(window).load(function() {$('#slider').nivoSlider({effect: 'sliceDownRight', slices:15, animSpeed: 300, pauseTime: 5000});});</script>
  <script type="text/javascript" src="/media/js/fancybox/jquery.fancybox-1.3.4.js"></script>
  <script type="text/javascript" src="/media/js/main.js"></script>
  <script type="text/javascript">$(function(){loadimg();loadgoogletranslate();loadsociallinks();});</script>
  
  
  
  <!--[if lt IE 7 ]>
    <script src="/media/js/libs/dd_belatedpng.js"></script>
    <script>DD_belatedPNG.fix('img, .png_bg'); // Fix any <img> or .png_bg bg-images. Also, please read goo.gl/mZiyb </script>
  <![endif]--><script>
    var _gaq = [['_setAccount', 'UA-26770326-1'], ['_trackPageview']];
    (function(d, t) {
    var g = d.createElement(t),
        s = d.getElementsByTagName(t)[0];
    g.async = true;
    g.src = ('https:' == location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    s.parentNode.insertBefore(g, s);
    })(document, 'script');
</script>
  
</body>
</html>