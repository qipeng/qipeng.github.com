﻿<html lang="en">
<head>
    <meta charset="">

  <!-- Always force latest IE rendering engine (even in intranet) & Chrome Frame
       Remove this if you use the .htaccess -->
  <meta http-equiv="X-UA-Compatible" content="">

  <!-- encoding must be specified within the first 512 bytes
        www.whatwg.org/specs/web-apps/current-work/multipage/semantics.html#charset -->

  <!-- meta element for compatibility mode needs to be before
        all elements except title & meta
        msdn.microsoft.com/en-us/library/cc288325(VS.85).aspx -->
  <!-- Chrome Frame is only invoked if meta element for
        compatibility mode is within the first 1K bytes
        code.google.com/p/chromium/issues/detail?id=23003 -->

  <title>[Coursera] Machine Learning Notes - Week 4-6</title>
  <meta name="description" content="Two batch files that I use to work with putty
">
  <meta name="author" content="Peng Qi">

  <!--  Mobile viewport optimized: j.mp/bplateviewport -->
  <meta name="viewport" content="">

    <link rel="shortcut icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/media/css/site.css" type="text/css">
  <link rel="stylesheet" href="/media/css/syntax.css" type="text/css">
  <link rel="stylesheet" href="/media/js/fancybox/jquery.fancybox-1.3.4.css" type="text/css">
      <!-- All JavaScript at the bottom, except for Modernizr which
        enables HTML5 elements & feature detects -->
    <script type="text/javascript" src="/media/js/libs/modernizr-1.7.min.js"></script>
    </head>
<body id="coursera-ml-note-2">
    <div id="container">
            <div id="main" role="main">
          <header class="banner clearfix">
          <h1>Peng Qi</h1>                              <nav class="main_nav">
    <ul>
                <li>
            <a title="Home Page"
                class="button home"
                href="/index.html">
                Home
            </a>
        </li>        <li>
            <a title="Research"
                class="button research"
                href="/research">
                Research
            </a>
        </li>        <li>
            <a title="Blog"
                class="button active blog"
                href="/blog">
                Blog
            </a>
        </li>        <li>
            <a title="Software"
                class="button software"
                href="/software">
                Software
            </a>
        </li>        <li>
            <a title="Misc"
                class="button misc"
                href="/misc">
                Me &amp; My ...
            </a>
        </li>    </ul>
</nav>
                    <div id="googletranslate" style="position:absolute;right:20px;bottom:5px"></div>
          </header>
          <div class="content-back">
          <div class="green-vline"></div>
          <div class="content-right">
          <div class="right-float">
<span class="lighter" style="font-size:14px;">Tags:</span><br/>
<ul class="tags clear">
<li>
    <a class="small" href="/blog/tags/coursera.html">
        coursera
    </a>
</li>
<li>
    <a class="small" href="/blog/tags/machine_learning.html">
        machine_learning
    </a>
</li>
<li>
    <a class="small" href="/blog/tags/note.html">
        note
    </a>
</li>
</ul>
</div>
          <div class="right-float"><div id="sociallinks" style="font-size:10px;">
          </div></div>
          </div>
          <div class="contentwrapper">
          <section class="content">
          <article class="post">

<a href="/blog">Blog</a> &nbsp;&gt;&nbsp; [Coursera] Machine Learning Notes - Week 4-6<br/>
<nav class="postnav before">
Previous:
None
<br/>

Next:
<a href="/blog/coursera-ml-note-1.html">[Coursera] Machine Learning Notes - Week 1-3</a>
</nav>

<div class="title"><h1 >
    [Coursera] Machine Learning Notes - Week 4-6
</h1></div>
<time datetime="2012-09-24">
    Posted: Mon, 24 Sep 2012
</time>

<div class="postcontent">
<p>
This post are the fresh notes of the current offering of Machine Learning course
on <a href="https://coursera.org" target="_blank">coursera.org</a>, which covers the
courses offered in Week 4 (Neural Networks: Representation) 
through Week 6 (Machine Learning System&nbsp;Design).</p>

<p>
<div class='title'><h2>Week&nbsp;4</h2></div>
<ul class='news'>
<li><span class='lighter'>Neural networks</span> are multi-layer models in which each layer can be envisioned as, I think, a <span class='lighter'>multivariate logistic regression</span> model. The <span class='lighter'>raw activation</span> is the input of the previous layer (including a bias unit) times the <span class='lighter'>network parameters</span> (or &#8220;weights&#8221;) inbetween; and the final output, the <span class='lighter'>activation</span> is the result of taking element-wise sigmoid nonlinearity of the raw&nbsp;activations.</li>
<li>Neural networks borrow its inspiration from the neuron cells, where input weights mimic the <span class='lighter'>dendrites</span>, while the output weights mimic the <span class='lighter'>Axons</span>. <span class='lighter'>Neuron cell bodies</span> are usually thought as computing a nonlinear function from the inputs to the&nbsp;outputs.</li>
<li>Neural networks can fit extremely complex functions, and by extracting more complex features of the input at each layer, the classfication result is often improved. Neural network classfication uses a notation of the &#8220;one-vs-all&#8221; scheme. That is, when we have multiple (&gt;= 3) labels, each label is denoted as an &#8220;all-zero-by-a-one&#8221; vector, e.g. class 1 = [1 0 0], class 2 = [0 1 0], class 3 = [0 0&nbsp;1].</li>
</ul>
</p>

<p>
<div class='title'><h2>Week&nbsp;5</h2></div>
<ul class='news'>
<li>The <span class='lighter'>cost function</span> of neural networks have similar forms to that of linear regression and logistic regression: an &#8220;output error&#8221; term plus the regularization term. Similar to logistic regression, the &#8220;1&#8221; unit or bias unit is not taken into consideration when doing parameter&nbsp;regularization.</li>
<li>The <span class='lighter'>back-propagation algorithm</span> propagate the error from the output layer all the way back to the first hidden layer (the layer next to the input layer), and use the error as well as the sigmoid gradient of the lower layer to compute the gradient of the weights inbetween. Similar to <span class='lighter'>forward propagation</span> that computes the activation of each layer and finally the output of the network, backprop is done layer-by-layer &#8211; only in the reverse&nbsp;order. </li>
<li>To make use of Matlab/Octave built-in or third-party vector-based optimization functions to obtain network parameters, the parameters, as well as their corresponding gradients, should be unrolled to form a single vector in pratical&nbsp;implementation.</li>
<li>To ensure that the gradient of the network parameters are correctly implemented, <span class='lighter'>gradient checking</span> should be performed to check if the gradients computed from analytical formulas are in accordance with those computed from approximation. Approximation can be done by choosing a small inteval length epsilon, and compute the two-sided approximate gradient (function value difference divided by the total interval length). As this gradient approximation is often computationally inefficient, gradient checking codes should be turned off before applying to pratical&nbsp;training.</li>
<li>Identical initialization will lead to identical gradients of the weights, thus the parameters will always remain identical between a given input unit and all the identically-initialized output units, resulting in uninformative (redundant) units. Thus, <span class='lighter'>random initialization</span> is essential to neural&nbsp;networks.</li>
</ul>
</p>

<p>
<div class='title'><h2>Week&nbsp;6</h2></div>
<ul class='news'>
<li>When evaluating a hypothesis, the best benchmark should be the error (or value of unregularized cost function) on the <span class='lighter'>test set</span>. But when multiple models are to be seleted from, a third <span class='lighter'>cross-validation set</span> should be used, thus the result from the test set is fair. Thus a usual pipeline of training, selecting a proper learning algorithm / model, and evaluating the model should be: first train the models on the <span class='lighter'>training set</span>, then fit the regularization value / choose a model according to the performance on the cross-validation set (or validation set), and finally evaluate the model on the test set. All three sets must be&nbsp;disjoint.</li>
<li><span class='lighter'>Learning curves</span> are the errors on the training set and validation set, respectively, plotted against the number of training data used. When the training error as well as validation error converge to a close large value, it&#8217;s likely that the model is of high bias (underfit), and adding features, decreasing regularization value should be considerable solutions. When the training error is small while the validation error remains large, it&#8217;s likely that the model is of high variance (overfit), and proper actions to take include carefully selecting features, reducing model parameters, and increasing regularization punishment. A proper learning curve should have a decreasing validation error and an increasing training error, and the former converging at a value usually slightly higher than that of the&nbsp;latter.</li>
<li><span class='lighter'>Error analysis</span> is an approach in which we analyse the characteristics of the falsely classfied data, and determine whether devising new features to deal with the misjudgements. It is also recommended to implement a &#8220;quick and dirty&#8221; learning algorithm for error analysis, to determine whether an algorithm is a good starting&nbsp;point.</li>
<li>When the data classes are skewed, e.g. have 99% positive examples with only 1% negative examples, <span class='lighter'>Precision</span> = #true positive / #predicted positive = #true positive / (#true positive + #false positive), <span class='lighter'>Recall</span> = #true positive / #all positive = #true positive / (#true positive + #false negative), and <span class='lighter'>F1 Score</span> = 2 * Precision * Recall / (Precision + Recall) are often superior error metrics than <span class='lighter'>Accuracy</span> = (#true postive + #true negative) / #all&nbsp;data.</li>
<li><span class='lighter'>Large amount of data</span> is helpful when (i) our model is of high variance (overfitting), as more data can make it difficult for the model to overfit the data, *<span class="caps">AND</span>* (ii) the features are enough for a human expert to give good predictions, i.e. giving enough information about the desired output, or more data will not&nbsp;help.</li>
</ul>
</p>

<p>
<div class='title'><h2>See&nbsp;Also&#8230;</h2></div>
<a href="corsera-ml-note-1.html">[Coursera] Machine Learning Notes - Week&nbsp;1-3</a>
</p></div>

<nav class="postnav after">
Previous:
None
<br/>

Next:
<a href="/blog/coursera-ml-note-1.html">[Coursera] Machine Learning Notes - Week 1-3</a>
</nav>

<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'pengqishomepage'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>
</article>          </section>
          </div>
          </div>
      </div>
      </div> <!--! end of #container -->
  <footer>
      <div id="designlogo"><a href="http://qipeng.github.com/misc/homepage.html" target="_blank"><span style="color:#11bb22;">Designed</span>by<br>
    <span style="padding-left:40px">Qi<span style="color:#11bb22;">Peng</span></span></a>
    <br><span style="font-size:10px;text-align:center;">Powered by <a href="http://hyde.github.com/" target="_blank" class="hyde">hyde</a>.</span></div>
      <p style="text-align:center">&copy; <a href="http://qipeng.github.com/">Peng Qi</a>, 2012. Hosted by <a href="http://www.github.com">GitHub</a>.</p>
  </footer>
    
  <link href='http://fonts.googleapis.com/css?family=Poly|Open+Sans' rel='stylesheet' type='text/css'>
  
    <!-- Javascript at the bottom for fast page loading -->
    <!-- Grab Google CDN's jQuery, with a protocol relative URL; fall back to local if necessary -->
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.js"></script>
  <script>window.jQuery || document.write('<script src="/media/js/libs/jquery-1.7.2.min.js">\x3C/script>')</script>
  
  <script type="text/javascript" src="/media/js/fancybox/jquery.fancybox-1.3.4.js"></script>
  <script type="text/javascript" src="/media/js/main.js"></script>
  <script type="text/javascript">$(function(){loadimg();loadgoogletranslate();loadsociallinks();})</script>
  
  <!--[if lt IE 7 ]>
    <script src="/media/js/libs/dd_belatedpng.js"></script>
    <script>DD_belatedPNG.fix('img, .png_bg'); // Fix any <img> or .png_bg bg-images. Also, please read goo.gl/mZiyb </script>
  <![endif]-->﻿<script>
    var _gaq = [['_setAccount', 'UA-26770326-1'], ['_trackPageview']];
    (function(d, t) {
    var g = d.createElement(t),
        s = d.getElementsByTagName(t)[0];
    g.async = true;
    g.src = ('https:' == location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    s.parentNode.insertBefore(g, s);
    })(document, 'script');
</script>
  </body>
</html>